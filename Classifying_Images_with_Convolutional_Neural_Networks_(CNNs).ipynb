{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy/WIpljtudi3aVzg9c/zR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kilos11/Tensoflow-by-Ricardo-Solinzki/blob/main/Classifying_Images_with_Convolutional_Neural_Networks_(CNNs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filtering Images**"
      ],
      "metadata": {
        "id": "T5osZgRjh5mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s5uYOzVhioy"
      },
      "outputs": [],
      "source": [
        "#Convolutional Neural Networks (CNNs)\n",
        "'''\n",
        "A traditional neural network receives a series of input values, multiplies each\n",
        "input value by a weight, and passes the processed data through a series of layers.\n",
        "This approach is fine for general-purpose data analysis, but it’s not sufficient for\n",
        "processing images and similar 2-D/3-D data. Image classification requires convo￾lution, and for this reason, neural networks intended for image classification are\n",
        "called convolutional neural networks, or CNNs.\n",
        "CNNs resemble regular neural networks in a number of ways, but they have two\n",
        "distinguishing characteristics:\n",
        "» A CNN contains convolution layers that use rectangular filters to perform\n",
        "convolution.\n",
        "» A CNN uses pooling layers to reduce the dimensionality of output images.\n",
        "\n",
        "Creating convolution layers:\n",
        "In a TensorFlow application, an image is a tensor that contains a matrix for each of\n",
        "an image’s channels. By channels, I mean the components that make up the image’s\n",
        "pixels. For example, a grayscale image has one channel, so its tensor consists of one\n",
        "matrix. An RGB image has three channels, so its tensor will have three channels.\n",
        "A convolution layer accepts a batch of images, performs convolution with a set of\n",
        "filters, and returns an output tensor containing the convolution results. The size\n",
        "of each output image depends on the size of the input images and the use of pad￾ding in the convolution.\n",
        "You can create a convolution layer by calling tf.layers.conv2d. Table 8-1 lists\n",
        "the parameters of this function and presents the default value of each.\n",
        "\n",
        "Creating pooling layers:\n",
        "A convolution layer produces an output image for each filter, so a CNN with many\n",
        "filters will produce many images. These images require a great deal of memory, so\n",
        "developers reduce the size of the images by following convolution layers with\n",
        "pooling layers.\n",
        "A pooling layer subdivides an image’s pixels into rectangular blocks and replaces\n",
        "each block with a single pixel. Figure  8-5 shows how this process works. The\n",
        "pooling operation divides a 9-x-8 matrix into 3-x-2 blocks and replaces each\n",
        "block with a single value.\n",
        "As with tf.layers.conv2d, the shape of the input tensor depends on data_for￾mat.\n",
        "If data_format is channels_last, the input tensor’s shape should be [batch_\n",
        "size, height, width, channels]. If data_format is channels_first, the input\n",
        "tensor’s shape should be [batch_size, channels, height, width]. Regardless of\n",
        "data_format, each element in the input tensor must be a tf.float32.\n",
        "To set the height and width of the block used for pooling, you need to assign\n",
        "pool_size to a list or tuple of two integers. For the pooling illustrated in Figure 8-5,\n",
        "the application set pool_size to [2, 2].\n",
        "strides identifies how much the block shifts (in pixels) from one pooling opera￾tion to the next.\n",
        "If the horizontal shift equals the vertical shift, you can set strides\n",
        "to one integer. If not, you can set strides to a tuple or list of two integers, where\n",
        "the first sets the vertical shift and the second sets the horizontal shift. For the\n",
        "pooling illustrated in Figure 8-5, the application set strides to 2.\n",
        "If a pooling operation involves a point near the image’s border, the computation\n",
        "will depend on the padding parameter. If you set padding to valid, the pooling\n",
        "won’t take border pixels into account. If you set padding to same, the function will\n",
        "pad the image with zeros before pooling its values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Putting Theory into Practice*"
      ],
      "metadata": {
        "id": "a9r19VRElNRo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-pjwqH9lTLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}